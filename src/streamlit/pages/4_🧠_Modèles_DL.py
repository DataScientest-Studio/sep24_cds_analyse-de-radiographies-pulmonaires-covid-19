import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
from utils import interactive_image


st.set_page_config(page_title="ModÃ¨les de Deep Learning", layout="wide")


st.title("ModÃ¨les de Deep Learning")

st.write("""
Les modÃ¨les **CNN prÃ©entraÃ®nÃ©s fine-tunÃ©s** ont largement surpassÃ© les modÃ¨les classiques de machine learning, grÃ¢ce Ã  leur capacitÃ© Ã  capturer des caractÃ©ristiques complexes dans les images mÃ©dicales.
""")

st.markdown("---")
st.write("## ğŸ§  ModÃ¨les explorÃ©s")

with st.expander("ğŸ“Œ VGG16"):
    st.write("""
    DÃ©veloppÃ© par lâ€™Ã©quipe du Visual Geometry Group (VGG) Ã  lâ€™UniversitÃ© dâ€™Oxford, VGG16 a Ã©tÃ© proposÃ© en 2014 et a marquÃ© une avancÃ©e majeure dans la vision par ordinateur. Son architecture simple et profonde repose sur des **convolutions 3x3 empilÃ©es**.  
    **F1-score : 99.31 %, Accuracy : 99.31 %**
    """)

with st.expander("ğŸ“Œ InceptionV3"):
    st.write("""
    ModÃ¨le introduit par Google en 2015, InceptionV3 amÃ©liore les versions prÃ©cÃ©dentes dâ€™Inception/GoogLeNet. Il utilise des blocs "Inception" composÃ©s de **convolutions de diffÃ©rentes tailles**, ce qui permet de capter plusieurs Ã©chelles d'information simultanÃ©ment.  
    **F1-score : 99.02 %, Accuracy : 99.02 %**
    """)

with st.expander("ğŸ“Œ LeNet-5"):
    st.write("""
    Lâ€™un des tout premiers CNN opÃ©rationnels, proposÃ© par Yann LeCun en 1998. UtilisÃ© initialement pour la reconnaissance de chiffres manuscrits (MNIST), LeNet est un modÃ¨le simple mais historique, ayant posÃ© les bases du deep learning moderne.  
    **F1-score : 91 %, Accuracy : 93 %**
    """)

with st.expander("ğŸ“Œ ResNet"):
    st.write("""
    ProposÃ© en 2015 par Kaiming He (Microsoft Research), ResNet introduit les **connexions rÃ©siduelles**, qui permettent dâ€™entraÃ®ner des rÃ©seaux trÃ¨s profonds sans perte de performance. Cette innovation a rÃ©volutionnÃ© l'apprentissage profond.  
    **F1-score : 99.19 %, Accuracy : 99.19 %**
    """)

with st.expander("ğŸ“Œ EfficientNetB0"):
    st.write("""
    PrÃ©sentÃ© par Google Brain en 2019, EfficientNet introduit un **scaling uniforme** des dimensions (profondeur, largeur, rÃ©solution) du rÃ©seau. Il atteint une **meilleure efficacitÃ© et prÃ©cision** avec un nombre de paramÃ¨tres rÃ©duit.  
    **F1-score : 99.08 %, Accuracy : 99.08 %**
    """)

with st.expander("ğŸ“Œ DenseNet-121"):
    st.write("""
    ProposÃ© en 2017 par Gao Huang, DenseNet se distingue par sa **connectivitÃ© dense entre les couches**. Chaque couche reÃ§oit comme entrÃ©e les sorties de toutes les couches prÃ©cÃ©dentes dans le bloc. Cette stratÃ©gie favorise une meilleure rÃ©utilisation des caractÃ©ristiques extraites.  
    **F1-score : 99.04 %, Accuracy : 99.04 %**
    """)

st.write("""
### âœ… Conclusion et tableau de synthÃ¨se
Nette amÃ©lioration par rapport aux modÃ¨les de machine learning classiques : **F1-score global > 98â€¯%** pour la classification 3 classes (hors LeNet qui est Ã  90â€¯%).
""")
st.image("src/images/DeepSynthese.png", caption="SynthÃ¨se des performances des modÃ¨les CNN", width=750)

st.markdown("---")
st.subheader("ğŸ”§ Optimisation des modÃ¨les deep learning")

with st.expander("ğŸ“ Effet de la taille des images"):
    st.write("""
    Le graphique ci-dessus illustre lâ€™Ã©volution de la prÃ©cision et de la loss pour diffÃ©rentes tailles dâ€™images (32Ã—32, 64Ã—64, 128Ã—128, 240Ã—240), en fonction du nombre dâ€™Ã©poques.  
    On observe un gain notable en prÃ©cision de validation, passant de **~80 %** avec des images 32Ã—32 Ã  **plus de 90 %** avec des images 240Ã—240.  
    Contrairement aux modÃ¨les classiques, les CNN bÃ©nÃ©ficient dâ€™images en haute rÃ©solution.  
    **â¡ï¸ Les images 240Ã—240 offrent le meilleur compromis performance/prÃ©cision.**
    """)

with st.expander("ğŸš« Impact de la classe dâ€™opacitÃ© pulmonaire"):
    st.write("""
    Dans la classification 4 classes, la classe dâ€™opacitÃ© pulmonaire nâ€™est correctement prÃ©dite que dans **82 %** des cas, bien en dessous des autres.  
    Elle regroupe des pathologies non-COVID trÃ¨s diverses et peu homogÃ¨nes.  
    En retirant cette classe, la classification (3 classes) gagne en prÃ©cision (souvent >95â€¯%).  
    **â¡ï¸ DÃ©cision : retirer la classe dâ€™opacitÃ© pulmonaire pour amÃ©liorer la clartÃ© du modÃ¨le.**
    """)
    st.image("src/images/umap_sans.png", caption="ReprÃ©sentation UMAP sans la classe dâ€™opacitÃ©", width=700)

with st.expander("ğŸ” Optimisation des hyperparamÃ¨tres avec Optuna / Keras Tuner"):
    st.write("""
    Lâ€™optimisation des hyperparamÃ¨tres sur EfficientNet a permis un gain significatif de performance :
    - ğŸ“ˆ Scores par classe jusquâ€™Ã  **99 %** (contre 95â€¯% sans tuning)
    - ğŸ§ª Tuning effectuÃ© sur :  
        - le **learning rate**  
        - la **taille des couches denses**  
        - le **dropout**

    â¡ï¸ L'impact est particuliÃ¨rement visible dans les matrices de confusion aprÃ¨s tuning.
    """)

with st.expander("ğŸ˜· Effet des masques sur les performances"):
    st.write("""
    Test effectuÃ© avec LeNet sur deux jeux de donnÃ©es : avec et sans masques.  
    RÃ©sultat :  
    - Les masques entraÃ®nent une **dÃ©gradation systÃ©matique** des performances (PrÃ©cision, Rappel, F1).  
    - Cela pourrait sâ€™expliquer par la **perte dâ€™informations clÃ©s** dans la zone du visage ou du thorax.

    **â¡ï¸ Conclusion : lâ€™usage des masques, dans ce cas, nâ€™est pas bÃ©nÃ©fique pour l'entraÃ®nement.**
    """)

st.markdown("---")
st.subheader("ğŸ§ª Essai avec une radiographie")
uploaded_file = st.file_uploader("TÃ©lÃ©versez une radiographie", type=["jpg", "jpeg", "png"])

@st.cache_resource
def load_model():
    return tf.keras.models.load_model("models/efficientnet_final.h5")

model = load_model()
class_names = ["COVID", "Normal", "Viral Pneumonia"]

def preprocess_image(image):
    image = image.convert("RGB").resize((240, 240))
    return np.expand_dims(np.array(image) / 255.0, axis=0)

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Image tÃ©lÃ©versÃ©e", use_container_width=True)

    with st.spinner("PrÃ©diction en cours..."):
        input_tensor = preprocess_image(image)
        predictions = model.predict(input_tensor)[0]
        predicted_class = class_names[np.argmax(predictions)]
        confidence = 100 * np.max(predictions)

    st.markdown(f"**Classe prÃ©dite :** `{predicted_class}`")
    st.markdown(f"**Confiance :** `{confidence:.2f}%`")
    st.bar_chart(dict(zip(class_names, predictions)))
