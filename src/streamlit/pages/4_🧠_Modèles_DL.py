import os
import streamlit as st
import pandas as pd
import tensorflow as tf
import numpy as np
from PIL import Image
from utils import interactive_image
import plotly.express as px
from codecarbon import EmissionsTracker
import gdown
from tensorflow.keras.applications.efficientnet import preprocess_input
import torch
from torchvision import transforms
from torch import nn
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights
from torch import nn



st.set_page_config(layout="wide")
st.title("üìä R√©sultats des mod√®les deep learning")

# M√©thodologie
st.header("üîß M√©thodologie")
st.markdown("""
- **Test d'un CNN de r√©f√©rence (LeNet)** puis de plusieurs mod√®les repr√©sentatifs d'√©volutions successives.  
Pour chacun de ces mod√®les, la logique suivante a √©t√© appliqu√©e :  
- **Transfer learning** sur la base de mod√®les pr√©-entra√Æn√©s ImageNet
- **Optimisation d'hyper-param√®tres** par keras-tuner ou optuna (couches de classification en particulier : nb de couches/neurones)
- **Fine‚Äëtuning** via d√©gel des derni√®res couches de convolution des mod√®les pr√©-entra√Æn√©s
- **Suppression de la classe 'Opacit√© pulmonaire'** ‚Üí uniquement Covid, Normal, Pneumonie virale.  
        La classe d‚Äôopacit√© pulmonaire est d√©finie comme regroupant des cas d‚Äôinfections pulmonaires non li√©es au COVID-19, une d√©finition large et peu sp√©cifique.
        Il est probable qu‚Äôelle contienne un m√©lange h√©t√©rog√®ne de pathologies pulmonaires. Sa d√©tection √©tait moins bonne, avec des r√©sultats globaux de 4% √† 5% inf√©rieurs.
""")

# Donn√©es enrichies avec ann√©es
data = [
    {"Ann√©e": 1998, "Mod√®le": "LeNet", "Params totaux": 61111, "Params fine‚Äëtuning": 61111, "Temps/epoch (s)": 25, "Pr√©cision (%)": 91.36, "Rappel (%)": 90.60, "F1-score (%)": 90.78},
    {"Ann√©e": 2015, "Mod√®le": "Inception", "Params totaux": 22328099, "Params fine‚Äëtuning": 22293667, "Temps/epoch (s)": 76, "Pr√©cision (%)": 98.55, "Rappel (%)": 98.54, "F1-score (%)": 98.55},
    {"Ann√©e": 2015, "Mod√®le": "ResNet", "Params totaux": 29886340, "Params fine‚Äëtuning": 6298628, "Temps/epoch (s)": 150, "Pr√©cision (%)": 99.30, "Rappel (%)": 98.85, "F1-score (%)": 99.08},
    {"Ann√©e": 2019, "Mod√®le": "EfficientNetB0", "Params totaux": 5701286, "Params fine‚Äëtuning": 5656703, "Temps/epoch (s)": 66, "Pr√©cision (%)": 99.08, "Rappel (%)": 99.08, "F1-score (%)": 99.08},
    {"Ann√©e": 2017, "Mod√®le": "DenseNet-121", "Params totaux": 6956931, "Params fine‚Äëtuning": 4588035, "Temps/epoch (s)": 115, "Pr√©cision (%)": 98.49, "Rappel (%)": 98.48, "F1-score (%)": 98.48},
    {"Ann√©e": 2014, "Mod√®le": "VGG16", "Params totaux": 134272835, "Params fine‚Äëtuning": 126637571, "Temps/epoch (s)": 100, "Pr√©cision (%)": 99.31, "Rappel (%)": 99.31, "F1-score (%)": 99.31},
]

# Cr√©ation du DataFrame tri√©
df = pd.DataFrame(data).sort_values("Ann√©e")

st.header("üìã Performances par mod√®le (3‚ÄØclasses)")
st.dataframe(df.style.format({
    "Params totaux": "{:,.0f}",
    "Params fine‚Äëtuning": "{:,.0f}",
    "Temps/epoch (s)": "{:.0f}",
    "Pr√©cision (%)": "{:.2f}",
    "Rappel (%)": "{:.2f}",
    "F1-score (%)": "{:.2f}",
}), hide_index=True)

# Visualisations

st.header("üìà Comparaisons visuelles")

# Transformation des colonnes pour line plot
melted = df.melt(id_vars="Mod√®le", value_vars=["Pr√©cision (%)", "Rappel (%)", "F1-score (%)"],
                 var_name="M√©trique", value_name="Valeur")

# Cr√©ation du graphique √† barres
fig2 = px.bar(
    melted,
    x="Mod√®le",
    y="Valeur",
    color="M√©trique",
    barmode="group",  # Affiche les barres c√¥te √† c√¥te
    labels={"Valeur": "Score (%)"}
)

fig2.update_layout(
    title="Comparaison des scores (Pr√©cision, Rappel, F1-score)",
    title_x=0.3,
    bargap=0.3,         # Espace entre les groupes de barres
    bargroupgap=0.15    # Espace entre les barres dans un groupe
)

st.plotly_chart(fig2, use_container_width=True)

fig1 = px.scatter(
    df,
    x="Params totaux",
    y="Temps/epoch (s)",
    size="F1-score (%)",
    color="Mod√®le",
    hover_name="Mod√®le",
    labels={
        "Params totaux": "Param√®tres (totaux)",
        "Temps/epoch (s)": "Temps/√©poque (s)",
        "F1-score (%)": "F1-score (%)"
    }
)

# Centrage du titre
fig1.update_layout(title="Temps d'entra√Ænement vs Taille du mod√®le", title_x=0.3)
st.plotly_chart(fig1, use_container_width=True)


# Focus sur EfficientNet
st.header("‚≠ê Focus sur **EfficientNetB0**")
eff = df[df.Mod√®le=="EfficientNetB0"].iloc[0]
st.markdown(f"""
- **Ann√©e**‚ÄØ: {eff["Ann√©e"]} ‚Üí mod√®le r√©cent et optimis√©  
- **Params totaux**‚ÄØ: {eff["Params totaux"]:,} (~5.7‚ÄØM)  
- **Temps/epoch**‚ÄØ: {eff["Temps/epoch (s)"]}‚ÄØs ‚Äî deux fois plus rapide que ResNet et VGG  
- **F1‚Äëscore**‚ÄØ: {eff["F1-score (%)"]:.2f}‚ÄØ% ‚Üí ‚Üë haute performance tout en restant l√©ger

EfficientNetB0 incarne le compromis id√©al **sobri√©t√© vs performance**, permettant d'obtenir d'excellents r√©sultats (‚âà‚ÄØ99‚ÄØ%) avec un mod√®le compact et rapide, id√©al pour le d√©ploiement.
""")

st.markdown("""
**‚úÖ Conclusion :**
- Tous les mod√®les surpassent 98‚ÄØ% de F1‚Äëscore, EfficientNetB0 se distingue par sa compacit√© et son efficacit√©.
- Utile pour les d√©ploiements contraints en ressources (cloud limit√©, mobilit√©...).
""")


st.markdown("---")
st.subheader("üß™ Essai avec une radiographie")
uploaded_file = st.file_uploader("Chargez une radiographie", type=["jpg", "jpeg", "png"])

@st.cache_resource
def load_model():
    return tf.keras.models.load_model("src/models/efficientnet_optimized.h5")

#model = load_model()

#class_names = ["COVID", "Normal", "Viral Pneumonia"]

def preprocess_image(image_pil):
    image_resized = image_pil.convert("RGB").resize((240, 240))
    img_array = np.array(image_resized) 
    img_array_preprocessed = preprocess_input(img_array)
    input_tensor = np.expand_dims(img_array_preprocessed, axis=0)    
    return input_tensor

def preprocess_image(image):
    image = image.convert("RGB").resize((240, 240))
    img_array = np.array(image)
    img_array = preprocess_input(img_array)  
    return np.expand_dims(img_array, axis=0)


def predict_image(image_path, model, class_names, device="cpu"):
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((240, 240)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])

    image = image_path.convert("RGB")
    input_tensor = transform(image).unsqueeze(0).to(device)  

    with torch.no_grad():
        outputs = model(input_tensor)
        probs = torch.nn.functional.softmax(outputs[0], dim=0)
        predicted_idx = torch.argmax(probs).item()
        predicted_class = class_names[predicted_idx]
        confidence = probs[predicted_idx].item() * 100

    #print(f"Pr√©diction : {predicted_class} ({confidence*100:.2f}%)")
    return predicted_class, confidence, probs

class EfficientNetClassifierOptimized(nn.Module):
    def __init__(self, num_classes=4, fine_tune=False):
        super(EfficientNetClassifierOptimized, self).__init__()

        weights = EfficientNet_B0_Weights.IMAGENET1K_V1
        self.base_model = efficientnet_b0(weights=weights)

        for param in self.base_model.parameters():
            param.requires_grad = fine_tune

        in_features = self.base_model.classifier[1].in_features

        self.classifier = nn.Sequential(
            nn.BatchNorm1d(in_features),
            nn.Linear(in_features, 3072),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(3072, 768),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(768, num_classes)
        )

        self.base_model.classifier = nn.Identity()

    def forward(self, x):
        x = self.base_model(x)
        x = self.classifier(x)
        return x
    
model = EfficientNetClassifierOptimized(num_classes=4)
model.load_state_dict(torch.load("models/efficentnetB0.pth", map_location="cpu"))
model.eval()    

class_names = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Image charg√©e")

    # Initialisation du tracker
    tracker = EmissionsTracker(project_name="streamlit_inference")
    tracker.start()

    with st.spinner("Pr√©diction en cours..."):
        #input_tensor = preprocess_image(image)
        #predictions = model.predict(input_tensor)[0]
        predicted_class, confidence, predictions =  predict_image(image, model, class_names)
        #st.markdown(predictions)
        #predicted_class = class_names[np.argmax(predictions)]
        #confidence = 100 * np.max(predictions)

    st.markdown(f"**Classe pr√©dite :** `{predicted_class}`")
    st.markdown(f"**Confiance :** `{confidence:.2f}%`")
    #st.bar_chart(dict(zip(class_names, predictions)))
    st.markdown("### R√©partition des probabilit√©s")    
    #predictions = predictions.cpu().numpy()
    #df_probs = pd.DataFrame({
    #    "Classe": class_names,
    #    "Probabilit√© (%)": [round(p * 100, 2) for p in predictions]
    #}).set_index('Classe')
    #st.bar_chart(df_probs)

    df = pd.DataFrame({
        'Classe': class_names,
        'Probabilit√© (%)': [round(p * 100, 2) for p in predictions.cpu().numpy()]
    })

    fig = px.bar(df, x='Classe', y='Probabilit√© (%)', text='Probabilit√© (%)')

    # Inclinaison des labels √† 45¬∞
    fig.update_layout(
        xaxis_tickangle=-45,
        title="R√©partition des probabilit√©s",
        yaxis_title="Probabilit√© (%)",
        xaxis_title="Classe"
    )

    # Affichage dans Streamlit
    st.plotly_chart(fig, use_container_width=True)

    # Arr√™t du tracker et affichage des √©missions
    tracker.stop()
    st.write(f"√âmissions estim√©es lors de l'inf√©rence : {tracker.final_emissions*1000:.2e} g CO‚ÇÇ (Estimation Code Carbone)")
