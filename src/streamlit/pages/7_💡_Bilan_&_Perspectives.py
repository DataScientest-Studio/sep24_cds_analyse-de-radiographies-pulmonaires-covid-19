import streamlit as st
from utils import interactive_image

st.set_page_config(page_title="Bilan et perspectives", layout="wide")


st.title("Bilan et perspectives")

st.subheader("R√©sultats obtenus")
st.write("""
Les mod√®les test√©s atteignent globalement d'excellents r√©sultats (autour de 99 % de F1-score).
Le mod√®le **EfficientNetB0** a √©t√© retenu pour la d√©mo finale en raison de son **excellent compromis entre performance et co√ªt d'entra√Ænement**.  
Il a atteint un **F1-score pond√©r√© de 99.08 %**.
""")

st.subheader("Difficult√©s rencontr√©es")
st.write("""
- **Donn√©es non homog√®nes** : forte variabilit√© des images selon leur origine.
- **Classes d√©s√©quilibr√©es** : certains labels sont sous-repr√©sent√©s, rendant l'apprentissage plus difficile.
- **Infrastructure GPU n√©cessaire** : les entra√Ænements avanc√©s n√©cessitent des ressources que nos PC personnels ne permettaient pas.  
  L‚Äôusage des GPU gratuits de **Kaggle (30h/semaine)** a √©t√© essentiel pour tester le d√©gel des couches convolutives.
- **Gestion de la m√©moire GPU** : lors du d√©gel de plusieurs blocs convolutifs (ex. : VGG16 en 4 classes), il a √©t√© n√©cessaire de r√©duire la taille des batchs (batch = 32).
- **Choix de la taille des batchs** :  
  - Trop petite : mauvais apprentissage (~20 % d‚Äôaccuracy en VGG16 3 classes avec batch=32).  
  - Trop grande : overfitting ou crash m√©moire.  
  - **Compromis id√©al identifi√© autour de batch=32**, selon les r√©sultats de la recherche d‚Äôhyperparam√®tres.
- **Pr√©traitement des images** : divergence des m√©thodes selon les cas (√©limination des anomalies, contraste, bruit‚Ä¶).
- **Temps limit√©** : projet men√© en parall√®le de la formation et des obligations professionnelles.
""")

st.subheader("Perspectives futures")
st.write("""
- **Int√©gration de m√©tadonn√©es cliniques** : √¢ge, sexe, ant√©c√©dents, sympt√¥mes‚Ä¶
- **Exploration de nouvelles architectures** :  
  Ex. : **Gravitational Search Algorithm** pour optimiser les hyperparam√®tres.
- **Am√©lioration de l‚Äôinterpr√©tabilit√©** :  
  Le mod√®le **DenseNet-121 + Vision Transformer** permet une meilleure compr√©hension via des **attention maps** et **Grad-CAM++**.
""")

st.set_page_config(page_title="Mod√®les avanc√©s", layout="wide")



st.subheader("Mod√®les Avanc√©s")
st.write("""
Les mod√®les avanc√©s explorent la combinaison de **CNN classiques avec des modules d‚Äôattention** ou des architectures de type **Transformer**.
""")
st.markdown("---")
st.subheader("üî¨ Architectures hybrides explor√©es")

with st.expander("üß† DenseNet-121 + Vision Transformer (ViT)"):
    st.write("""
    DenseNet-121 est un r√©seau CNN structur√© en quatre blocs denses. Chaque couche re√ßoit les sorties de toutes les couches pr√©c√©dentes, am√©liorant ainsi la r√©utilisation des caract√©ristiques extraites et limitant la disparition du gradient.  
    ViT (Vision Transformer), quant √† lui, segmente l‚Äôimage en **patches** pour appliquer une **self-attention globale**.  
    Cette approche hybride exploite **les forces combin√©es** :  
    - locales ‚Üí CNN  
    - globales ‚Üí Transformer  

    **F1-score pond√©r√© : 0.99, Pr√©cision pond√©r√©e : 0.99**  
    Optimis√© via **Grid Search** sur :  
    - le learning rate  
    - le taux de dropout  
    - la taille des batchs
    """)

with st.expander("üì¶ VGG16 + SE (Squeeze-and-Excitation)"):
    st.write("""
    VGG16 est un CNN profond √† 16 couches, introduit en 2014.  
    Les blocs SE (Squeeze-and-Excitation) appliquent une **attention par canal**, permettant au r√©seau de **recalibrer dynamiquement** les canaux d‚Äôactivation.  
    Cette attention est ins√©r√©e apr√®s chaque bloc convolutif, avant le max-pooling.

    **F1-score pond√©r√© : 0.9864, Pr√©cision pond√©r√©e : 0.9864**
    """)

st.markdown("---")
st.subheader("üìâ Conclusion")
st.write("""
Contrairement aux attentes, ces mod√®les avanc√©s **ne surpassent pas significativement** les mod√®les CNN fine-tun√©s comme EfficientNet ou InceptionV3.  
En revanche, leur co√ªt en calcul est **nettement plus √©lev√©**, notamment √† cause des modules d‚Äôattention.
""")
