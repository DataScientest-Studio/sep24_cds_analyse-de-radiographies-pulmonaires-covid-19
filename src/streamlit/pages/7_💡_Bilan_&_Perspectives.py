import streamlit as st
from utils import interactive_image

st.set_page_config(page_title="Bilan et perspectives", layout="wide")

st.title("Bilan et perspectives")

st.subheader("R√©sultats obtenus")
st.write("""
Les mod√®les test√©s atteignent globalement d'excellents r√©sultats (autour de 99 % de f1-score).
Le mod√®le **EfficientNetB0** a √©t√© retenu pour la d√©monstration finale en raison de son **excellent compromis entre performance et co√ªt d'entra√Ænement**.  
Il a atteint un **f1-score pond√©r√© de 99.08 %**.
""")

st.subheader("Difficult√©s rencontr√©es")
st.write("""
- **Donn√©es non homog√®nes** : forte variabilit√© des images selon leur origine.
- **Classes d√©s√©quilibr√©es** : certains labels sont sous-repr√©sent√©s, rendant l'apprentissage plus difficile.
- **Infrastructure GPU n√©cessaire** : les entra√Ænements avanc√©s n√©cessitent des ressources que nos PC personnels ne permettaient pas.  
  L‚Äôusage des GPU gratuits de **Kaggle (30h/semaine)** a √©t√© essentiel pour tester le d√©gel des couches convolutives.
- **Gestion de la m√©moire GPU** : lors du d√©gel de plusieurs blocs convolutifs (ex. : VGG16 en 4 classes), il a √©t√© n√©cessaire de r√©duire la taille des batchs (batch = 32).
- **Choix de la taille des batchs** :  
  - Trop petite : mauvais apprentissage (~20 % d‚Äôaccuracy en VGG16 3 classes avec batch=32).  
  - Trop grande : overfitting ou crash m√©moire.  
  - **Compromis id√©al identifi√© autour de batch=32**, selon les r√©sultats de la recherche d‚Äôhyperparam√®tres.
- **Pr√©traitement des images** : divergence des m√©thodes selon les cas (√©limination des anomalies, contraste, bruit‚Ä¶).
- **Temps limit√©** : projet men√© en parall√®le de la formation et des obligations professionnelles.
""")

st.subheader("Perspectives futures")
st.write("""
- **Augmentation du jeu de donn√©es** : apport des sources de donn√©es cliniques suppl√©mentaires pour garantir la g√©n√©ralisation et limiter le biais d'apprentissage,
- **Int√©gration de m√©tadonn√©es cliniques** (si disponibles) : √¢ge, sexe, ant√©c√©dents, sympt√¥mes, r√©sultats biologiques, etc.,
- **Segmentation pr√©alable des poumons** : segmentation automatique des poumons (par exemple avec U-Net) avant la classification pour concentrer l‚Äôattention du mod√®le sur les r√©gions d‚Äôint√©r√™t et r√©duire l‚Äôinfluence du bruit hors poumon,
- **Extraction de textures avanc√©es** : ajout de descripteurs texturaux (par exemple GLCM, GLDM ou ondelettes) pour enrichir les features et mieux diff√©rencier les pathologies similaires,
- **Mise en place d'optimisateurs avanc√©s** : algorithmes (par exemple Adamax) pour optimiser la convergence et la stabilit√© du mod√®le,
- **Interpr√©tabilit√© avanc√©e** : utilisation des cartes d'attentions de mod√®les hybrides CNN & Vision Transformer, techniques r√©centes (SHAP, etc.),
- **Mise en oeuvre d'architectures avanc√©es** : 
  - Approches d'ensemble : plusieurs architectures CNN entra√Æn√©es s√©par√©ment dont dont les pr√©dictions sont aggr√©g√©es (moyenne ou vote majoritaire),
  - Architectures hybrides (CNN & ViT) : qui capturent √† la fois les d√©pendances locales et globales et qui apportent d'autres √©l√©ments d'interpr√©tabilit√©,
""")
with st.expander("üî¨ DenseNet-121 + Vision Transformer (ViT)"):
    st.write("""
    DenseNet-121 est un r√©seau CNN structur√© en quatre blocs denses. Chaque couche re√ßoit les sorties de toutes les couches pr√©c√©dentes, am√©liorant ainsi la r√©utilisation des caract√©ristiques extraites et limitant la disparition du gradient.  
    ViT (Vision Transformer), quant √† lui, segmente l‚Äôimage en patches pour appliquer une self-attention globale.  
    Cette approche hybride exploite les forces combin√©es :  
    - du **CNN** ‚Üí qui capture les d√©pendances **locales** 
    - du **Vision Transformer** ‚Üí qui capture les d√©pendances **globales** 

    **f1-score pond√©r√© : 0.99, pr√©cision pond√©r√©e : 0.99**  
    Optimis√© via Grid Search sur le learning rate, le taux de dropout, la taille des batchs
    """)
st.write("""
  - Int√©gration de modules d‚Äôattention : pour am√©liorer la focalisation du r√©seau sur les r√©gions critiques.
""")
with st.expander("üî¨ VGG16 + SE (Squeeze-and-Excitation)"):
    st.write("""
    VGG16 est un CNN profond √† 16 couches, introduit en 2014.  
    Les blocs **SE (Squeeze-and-Excitation)** appliquent une **attention par canal**, permettant au r√©seau de **recalibrer dynamiquement** les canaux d‚Äôactivation.  
    Cette attention est **ins√©r√©e apr√®s chaque bloc convolutif**, avant le max-pooling.
    **f1-score pond√©r√© : 0.9864, pr√©cision pond√©r√©e : 0.9864**
    """)
st.write(""" 
  ‚Üí Contrairement aux attentes, ces mod√®les avanc√©s ne surpassent pas significativement les mod√®les CNN fine-tun√©s comme EfficientNet ou InceptionV3.  
En revanche, leur co√ªt en calcul est plus √©lev√©, notamment √† cause des modules d‚Äôattention.
""")

st.subheader("Conclusion")

