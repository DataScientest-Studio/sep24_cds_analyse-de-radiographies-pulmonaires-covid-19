import streamlit as st
from utils import interactive_image


st.set_page_config(page_title="Mod√®les avanc√©s", layout="wide")



st.title("Mod√®les Avanc√©s")
st.write("""
Les mod√®les avanc√©s explorent la combinaison de **CNN classiques avec des modules d‚Äôattention** ou des architectures de type **Transformer**.
""")
st.markdown("---")
st.subheader("üî¨ Architectures hybrides explor√©es")

with st.expander("üß† DenseNet-121 + Vision Transformer (ViT)"):
    st.write("""
    DenseNet-121 est un r√©seau CNN structur√© en quatre blocs denses. Chaque couche re√ßoit les sorties de toutes les couches pr√©c√©dentes, am√©liorant ainsi la r√©utilisation des caract√©ristiques extraites et limitant la disparition du gradient.  
    ViT (Vision Transformer), quant √† lui, segmente l‚Äôimage en **patches** pour appliquer une **self-attention globale**.  
    Cette approche hybride exploite **les forces combin√©es** :  
    - locales ‚Üí CNN  
    - globales ‚Üí Transformer  

    **F1-score pond√©r√© : 0.99, Pr√©cision pond√©r√©e : 0.99**  
    Optimis√© via **Grid Search** sur :  
    - le learning rate  
    - le taux de dropout  
    - la taille des batchs
    """)

with st.expander("üì¶ VGG16 + SE (Squeeze-and-Excitation)"):
    st.write("""
    VGG16 est un CNN profond √† 16 couches, introduit en 2014.  
    Les blocs SE (Squeeze-and-Excitation) appliquent une **attention par canal**, permettant au r√©seau de **recalibrer dynamiquement** les canaux d‚Äôactivation.  
    Cette attention est ins√©r√©e apr√®s chaque bloc convolutif, avant le max-pooling.

    **F1-score pond√©r√© : 0.9864, Pr√©cision pond√©r√©e : 0.9864**
    """)

st.markdown("---")
st.subheader("üìâ Conclusion")
st.write("""
Contrairement aux attentes, ces mod√®les avanc√©s **ne surpassent pas significativement** les mod√®les CNN fine-tun√©s comme EfficientNet ou InceptionV3.  
En revanche, leur co√ªt en calcul est **nettement plus √©lev√©**, notamment √† cause des modules d‚Äôattention.
""")