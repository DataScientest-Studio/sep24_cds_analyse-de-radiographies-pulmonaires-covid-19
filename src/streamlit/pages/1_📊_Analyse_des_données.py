import streamlit as st
import pandas as pd
import plotly.express as px
from utils import interactive_image
import os
from PIL import Image
import cv2  
import random
import numpy as np

st.set_page_config(page_title="Analyse des Donn√©es", layout="wide")

st.title("Analyse des donn√©es")

palette_bar = {
    'Normal': 'green',
    'Opacit√© Pulmonaire': 'orange',
    'COVID-19': 'red',
    'Pneumonie virale': 'blue'}
classes_order = ['Normal', 'Opacit√© Pulmonaire', 'COVID-19', 'Pneumonie virale']


st.subheader("Exploration visuelle")

st.write("""
L'inspection visuelle de quelques images met en √©vidence que les radios sont dans l‚Äôensemble de tr√®s bonne qualit√©.
""")
interactive_image("src/images/InspectionVisuelle.png", "exemple")


st.subheader("Description du jeu de donn√©es")
st.write("""
Le jeu de donn√©es comprend 21 164 images r√©parties entre quatre classes : Normal (10192), Opacit√© pulmonaire (6012), COVID-19 (3615), Pneumonie virale (1345). Les images proviennent de diff√©rentes sources m√©dicales internationales.  
La distribution est in√©gale, avec 48% de radios normales et seulement 6% de pneumonies virales, ce qui peut poser des d√©fis pour l'apprentissage automatique.
""")

df_dist = pd.DataFrame({
    'Classe': ['Normal', 'Opacit√© Pulmonaire', 'COVID-19', 'Pneumonie virale'],
    'Nombre d\'images': [10192, 6012, 3615, 1345]
})

st.write("""Ci-dessous une r√©pr√©sentation de la r√©partition des classes dans le jeu de donn√©es :""")

fig = px.bar(
    df_dist,
    x='Classe',
    y="Nombre d'images",
    text="Nombre d'images",
    color='Classe',
    color_discrete_map=palette_bar)
fig.update_traces(textposition='outside')
fig.update_layout(
    xaxis_title="Classe",
    yaxis_title="Nombre d'images",
    showlegend=True
)
st.plotly_chart(fig, use_container_width=True)

st.subheader("Distribution de la variance par classe")


st.write("""Ci-dessous une r√©pr√©sentation de la variance par classe (plus la variance est √©lev√©e, plus l'image est complexe/textur√©e) :""")


script_dir = os.path.dirname(os.path.abspath(__file__))    
project_root = os.path.dirname(script_dir)    
input_filename = os.path.join(project_root, 'data', 'variance.csv')    
df_plot = pd.read_csv(input_filename)  


fig = px.violin(
    df_plot,
    x='classe',
    y='variance',
    color='classe',
    color_discrete_map=palette_bar,
    box=True,  
    points=False,
    category_orders={'classe': classes_order},
    labels={
        'classe': 'Classe de la radiographie',
        'variance': 'Variance des pixels'
    }
)
fig.update_layout(
    xaxis_title="Cat√©gorie",
    yaxis_title="Variance",
    legend_title="L√©gende"
)
st.plotly_chart(fig, use_container_width=True)

# Remplac√© par graphique interactif plotly en violin plot
# interactive_image("src/images/Variance.png", "exemple")

st.subheader("D√©tection d'anomalies")
st.write("""
Des anomalies ont √©t√© identifi√©es, telles que des doublons ou des images de faible qualit√©.
""")

st.write("""
Avec la m√©thode IQR sur l‚Äôintensit√© et l‚Äô√©cart-type, apr√®s normalisation de l‚Äôintensit√© (seuil √† 1,5 x IQR) : 285 outliers identifi√©s.  
Ci-dessous une visualisation de la r√©partition de l‚Äôintensit√© en fonction de l‚Äô√©cart-type sur les radios apr√®s normalisation :
""")


script_dir = os.path.dirname(os.path.abspath(__file__))    
project_root = os.path.dirname(script_dir)    
input_filename = os.path.join(project_root, 'data', 'iqr_outliers.csv')    
df_plot = pd.read_csv(input_filename)  

taille_mapping = {'Non': 5, 'Oui': 20} 
df_plot['taille_point'] = df_plot['est_outlier'].map(taille_mapping)

fig = px.scatter(
    df_plot,
    x='intensite_moyenne',
    y='ecart_type',
    color='classe',
    color_discrete_map=palette_bar,
    symbol='est_outlier',
    size='taille_point',         
    #symbol_map={'Non': 'circle', 'Oui': 'star-diamond'},
    category_orders={
        'classe': classes_order,
        'est_outlier': ['Non', 'Oui']
    },
    labels={
        'intensite_moyenne': 'Intensit√© Moyenne (Image Normalis√©e)',
        'ecart_type': '√âcart-Type des Pixels (Contraste/Texture)',
        'classe': 'Classe de la Radiographie',
        'est_outlier': 'Est un Outlier ?'
    },
    title='Distribution des Radiographies par Intensit√© et √âcart-Type'
)

fig.update_traces(hoverinfo='none', hovertemplate=None)
fig.update_layout(
    legend_title="L√©gendes",
    height=700 
)

st.plotly_chart(fig, use_container_width=True)


interactive_image("src/images/Intensite-ecart.png", "exemple")


st.write("#### Elimination des anomalies")

DESCRIPTIONS = {
    'Statistique': "Cette m√©thode fondamentale transforme chaque image en caract√©ristiques num√©riques (moyenne, contraste, entropie). Le score d'anomalie est bas√© sur la distance d'une image √† la distribution normale. La technique fonctionne tr√®s bien pour trouver les images tr√®s sombres ou vides.",
    'Isolation Forest': "Cette approche utilise un r√©seau de neurones VGG16 entra√Æn√© sur des images pour extraire des caract√©ristiques complexes. L'algorithme Isolation Forest isole ensuite les images qui sont s√©mantiquement diff√©rentes des autres. Cette approche est efficace pour trouver des textures ou des formes inhabituelles (pr√©sence de colliers, pacemakers, etc.)",
    'Auto-encoder': "Un r√©seau de neurones est entra√Æn√© √† compresser puis reconstruire les images du dataset. Il devient expert des radiographies 'typiques'. Une image qu'il peine √† reconstruire (erreur √©lev√©e) est consid√©r√©e comme anormale. C'est l'approche la plus sensible aux anomalies subtiles."
}

options = ["Statistique", "Isolation Forest", "Auto-encoder"]
selection = st.segmented_control(
    "",
    options,
    label_visibility="collapsed", 
    default="Statistique"
)

if selection == "Statistique":
    st.write("#### Approche Statistique")
    st.write(DESCRIPTIONS[selection])
    
    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'plot_data_statistique.csv')
    df_plot = pd.read_csv(input_filename)
    fig = px.scatter_3d(
            df_plot,
            x='Moyenne Normalis√©e',
            y='√âcart-type Normalis√©',
            z='Entropie Normalis√©e',
            color='score',
            size='score',
            size_max=20,
            color_continuous_scale=px.colors.sequential.Viridis,
        )
    fig.update_traces(marker=dict(opacity=0.8), hoverinfo='none', hovertemplate=None)
    fig.update_layout(margin=dict(l=0, r=0, b=0, t=40))
    st.plotly_chart(fig, use_container_width=True)

    st.write("Les 10 images les plus anormales trouv√©es :")

    method_key = selection.lower().replace(' ', '_')  
    for i in range(2):
        cols = st.columns(5)
        for j in range(5):
            rank = i * 5 + j + 1
            script_dir = os.path.dirname(os.path.abspath(__file__))    
            project_root = os.path.dirname(script_dir)    
            image_path = os.path.join(project_root, 'outliers_images', f"{method_key}_anomaly_{rank}.png")
            with cols[j]:
                try:
                    st.image(Image.open(image_path), use_container_width=True)
                except FileNotFoundError:
                    st.markdown(f"_(Image #{rank} non trouv√©e)_")    

elif selection == "Isolation Forest":
    st.write("#### Approche Machine Learning (Isolation Forest)")
    st.write(DESCRIPTIONS[selection])

    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'plot_data_isolation_forest.csv')
    df_plot = pd.read_csv(input_filename)
    
    score_values = df_plot['score'].values
    min_val, max_val = score_values.min(), score_values.max()
    df_plot['size_score'] = (score_values - min_val) / (max_val - min_val) if (max_val - min_val) > 0 else 0

    fig = px.scatter_3d(
        df_plot,
        x='PC1', y='PC2', z='PC3',
        color='score',
        size='size_score',
        size_max=20,
        color_continuous_scale=px.colors.sequential.Viridis,
    )
    fig.update_traces(marker=dict(opacity=0.8), hoverinfo='none', hovertemplate=None)
    fig.update_layout(margin=dict(l=0, r=0, b=0, t=40))
    st.plotly_chart(fig, use_container_width=True)

    st.write("Les 10 images les plus anormales trouv√©es :")


    method_key = selection.lower().replace(' ', '_')
    for i in range(2):
        cols = st.columns(5)
        for j in range(5):
            rank = i * 5 + j + 1
            script_dir = os.path.dirname(os.path.abspath(__file__))    
            project_root = os.path.dirname(script_dir)    
            image_path = os.path.join(project_root, 'outliers_images', f"{method_key}_anomaly_{rank}.png")
            with cols[j]:
                try:
                    st.image(Image.open(image_path), use_container_width=True)
                except FileNotFoundError:
                    st.markdown(f"_(Image #{rank} non trouv√©e)_")   

elif selection == "Auto-encoder":
    st.write("#### Approche Deep Learning (Auto-encodeur)")
    st.write(DESCRIPTIONS[selection])

    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'plot_data_autoencoder.csv')
    df_plot = pd.read_csv(input_filename)

    fig = px.scatter_3d(
        df_plot,
        x='Latent PC1', y='Latent PC2', z='Latent PC3',
        color='score',
        size='score',
        size_max=20,
        color_continuous_scale=px.colors.sequential.Viridis,
    )
    fig.update_traces(marker=dict(opacity=0.8), hoverinfo='none', hovertemplate=None)
    fig.update_layout(margin=dict(l=0, r=0, b=0, t=40))
    st.plotly_chart(fig, use_container_width=True)

    st.write("Les 10 images les plus anormales trouv√©es :")
    
    method_key = selection.lower().replace(' ', '_').replace('-', '')
    for i in range(2):
        cols = st.columns(5)
        for j in range(5):
            rank = i * 5 + j + 1
            script_dir = os.path.dirname(os.path.abspath(__file__))    
            project_root = os.path.dirname(script_dir)    
            image_path = os.path.join(project_root, 'outliers_images', f"{method_key}_anomaly_{rank}.png")
            with cols[j]:
                try:
                    st.image(Image.open(image_path), use_container_width=True)
                except FileNotFoundError:
                    st.markdown(f"_(Image #{rank} non trouv√©e)_")   



st.subheader("R√©ductions de dimensions")

options = ["PCA", "UMAP", "AE", "NMF"]
selection = st.segmented_control("", 
                                 options, 
                                 selection_mode="single",
                                 default="PCA"
                                )

palette = {
    'Normal': 'green',
    'COVID': 'red',
    'Lung_Opacity': 'orange',
    'Viral Pneumonia': 'blue'}


if selection == "PCA" :
    st.write("#### Analyse en Composantes Principales (PCA)")
    st.write("PCA trouve de nouveaux axes (appel√©s composantes principales) qui maximisent la variance (la dispersion) des donn√©es. Le premier axe capture le plus de variance possible, le deuxi√®me en capture le plus possible parmi ce qu'il reste, et ainsi de suite. C'est une m√©thode purement math√©matique et lin√©aire.")
    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'pca_3d_data.csv')    
    df_plot = pd.read_csv(input_filename)  
    fig = px.scatter_3d(
        df_plot,
        x='PCA 1',
        y='PCA 2',
        z='PCA 3',
        color='label', 
        title="Visualisation 3D PCA des radiographies pulmonaires",
        color_discrete_map=palette,
    )
    fig.update_traces(marker=dict(size=3, opacity=0.8))
    fig.update_layout(legend_title_text='Classe',margin=dict(l=0, r=0, b=0, t=0))
    fig.update_traces(hoverinfo='none', hovertemplate=None)
    st.plotly_chart(fig, use_container_width=True)

if selection == "UMAP" :
    st.write("#### Uniform Manifold Approximation and Projection (UMAP)")
    st.write("UMAP est une technique d'apprentissage de vari√©t√©s (manifold learning). Elle suppose que les donn√©es, m√™me si elles sont dans un grand espace, vivent en r√©alit√© sur une surface de plus faible dimension (la vari√©t√©). UMAP essaie de mod√©liser cette surface et de la d√©plier dans un espace plus petit tout en pr√©servant au mieux la structure topologique des donn√©es (qui est voisin de qui, localement et globalement).")
    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'umap_3d_data.csv')    
    df_plot = pd.read_csv(input_filename)  
    fig = px.scatter_3d(
        df_plot,
        x='UMAP 1',
        y='UMAP 2',
        z='UMAP 3',
        color='label', 
        title="Visualisation 3D UMAP des radiographies pulmonaires",
        color_discrete_map=palette,
    )
    fig.update_traces(marker=dict(size=3, opacity=0.8))
    fig.update_layout(legend_title_text='Classe',margin=dict(l=0, r=0, b=0, t=0))
    fig.update_traces(hoverinfo='none', hovertemplate=None)
    st.plotly_chart(fig, use_container_width=True)

    
elif selection == "AE" :
    st.write("#### Auto-Encoder (AE)")
    st.write("C'est un type de r√©seau de neurones qui apprend √† compresser les donn√©es (partie encodeur) en une repr√©sentation de faible dimension (le goulot d'√©tranglement ou bottleneck), puis √† les d√©compresser (partie d√©codeur) pour reconstruire l'entr√©e originale. En for√ßant le r√©seau √† recr√©er les donn√©es √† partir d'une version compress√©e, il apprend les caract√©ristiques les plus importantes.")
    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'ae_3d_data.csv')    
    df_plot = pd.read_csv(input_filename)  
    fig = px.scatter_3d(
        df_plot,
        x='AE 1',
        y='AE 2',
        z='AE 3',
        color='label', 
        title="Visualisation 3D AE des radiographies pulmonaires",
        color_discrete_map=palette,
    )
    fig.update_traces(marker=dict(size=3, opacity=0.8))
    fig.update_layout(legend_title_text='Classe',margin=dict(l=0, r=0, b=0, t=0))
    fig.update_traces(hoverinfo='none', hovertemplate=None)
    st.plotly_chart(fig, use_container_width=True)

    
if selection == "NMF" :
    st.write("#### Non-negative Matrix Factorization (NMF)")
    st.write("La NMF d√©compose une grande matrice de donn√©es (par exemple, des images ou des documents) en deux matrices plus petites. La contrainte essentielle est que toutes les valeurs dans les trois matrices doivent √™tre non-n√©gatives. Cela force la d√©composition √† √™tre additive.")
    script_dir = os.path.dirname(os.path.abspath(__file__))    
    project_root = os.path.dirname(script_dir)    
    input_filename = os.path.join(project_root, 'data', 'nmf_3d_data.csv')    
    df_plot = pd.read_csv(input_filename)  
    fig = px.scatter_3d(
        df_plot,
        x='NMF 1',
        y='NMF 2',
        z='NMF 3',
        color='label', 
        title="Visualisation 3D NMF des radiographies pulmonaires",
        color_discrete_map=palette,
    )
    fig.update_traces(marker=dict(size=3, opacity=0.8))
    fig.update_layout(legend_title_text='Classe',margin=dict(l=0, r=0, b=0, t=0))
    fig.update_traces(hoverinfo='none', hovertemplate=None)
    st.plotly_chart(fig, use_container_width=True)



st.subheader("Pr√©traitement")

st.write("Plusieurs techniques de pr√©traitement ont √©t√© appliqu√©es durant le projet. Ces √©tapes se sont av√©r√©es tr√®s utiles pour am√©liorer la performance des mod√®les de machine learning.")

st.write("#### Redimensionnement, normalisation et am√©lioration du contraste")

st.write("""Les images ont √©t√© redimensionn√©es √† 240 x 240 pixels et normalis√©es. En effet, il a √©t√© constat√© que 7 radiographies sur 10 ne sont pas normalis√©es. L'am√©lioration du contraste par la technique CLAHE a √©galement √©t√© test√©e. Elle am√©liore le contraste en l'√©galisant sur de petites zones locales de l'image, ce qui permet de rehausser les d√©tails fins sans sur-amplifier le bruit de mani√®re globale. Sur les radiographies, cette technique est tr√®s pertinente car elle fait ressortir les structures subtiles des tissus mous sans saturer les zones tr√®s denses comme les os, am√©liorant ainsi la visibilit√© pour le diagnostic.
""")

@st.cache_data 
def get_image_paths(folder):
    if not os.path.isdir(folder):
        return []
    supported_extensions = ('.png', '.jpg', '.jpeg')
    return [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(supported_extensions)]

def transform_image_randomly(pil_image):
    image_np = np.array(pil_image.convert('L'))
    if random.random() < 0.5: image_np = cv2.flip(image_np, 1) 
    h, w = image_np.shape
    angle = random.uniform(-10, 10)
    scale = random.uniform(0.9, 1.1)
    tx = random.uniform(-w * 0.05, w * 0.05)
    ty = random.uniform(-h * 0.05, h * 0.05)
    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, scale)    
    M[0, 2] += tx
    M[1, 2] += ty    
    transformed_image = cv2.warpAffine(image_np, M, (w, h), borderMode=cv2.BORDER_REPLICATE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    transformed_image = clahe.apply(transformed_image)
    normalized_image = transformed_image.astype(np.float32) / 255.0    
    return normalized_image


script_dir = os.path.dirname(os.path.abspath(__file__))
streamlit_dir = os.path.dirname(script_dir) 
IMAGE_DIR = os.path.join(streamlit_dir, 'images')

all_image_paths = get_image_paths(IMAGE_DIR)

st.write("#### Augmentation de Donn√©es")

st.write("Les images ont √©t√© enrichies par augmentation de donn√©es (retournements horizontaux, rotations, zooms, translations al√©atoires).")

if not all_image_paths:
    st.error(f"Aucune image trouv√©e dans le dossier '{IMAGE_DIR}'.")
    st.warning("Veuillez v√©rifier que le dossier existe et contient des images.")
else:
    if 'current_image_path' not in st.session_state or st.session_state.current_image_path not in all_image_paths:
        st.session_state.current_image_path = random.choice(all_image_paths)
        st.session_state.transformed_image = None   

    try:
        original_image = Image.open(st.session_state.current_image_path)
    except Exception as e:
        st.error(f"Erreur lors du chargement de l'image : {e}")
        original_image = None 

    control_col1, control_col2 = st.columns(2)
    with control_col1:
        if st.button("üîÑ Nouvelle image", use_container_width=True):
            st.session_state.current_image_path = random.choice(all_image_paths)
            st.session_state.transformed_image = None
            st.rerun()

    with control_col2:
        is_disabled = (original_image is None)
        if st.button("‚ú® Transformation", use_container_width=True, disabled=is_disabled):
            if original_image:
                st.session_state.transformed_image = transform_image_randomly(original_image)
                
    image_col1, image_col2 = st.columns(2)

    with image_col1:
        st.markdown("<h5 style='text-align: center;'>Image Originale</h5>", unsafe_allow_html=True)
        if original_image:
            left_space, img_container, right_space = st.columns([1, 2, 1])
            with img_container:
                file_name = os.path.basename(st.session_state.current_image_path)
                st.image(original_image, caption=f"Fichier : {file_name}", width=300) 

    with image_col2:
        st.markdown("<h5 style='text-align: center;'>Image Transform√©e</h5>", unsafe_allow_html=True)
        if st.session_state.transformed_image is not None:
            left_space, img_container, right_space = st.columns([1, 2, 1])
            with img_container:
                st.image(st.session_state.transformed_image, caption="R√©sultat de l'augmentation", width=300)
        else:
            st.info("L'image transform√©e apparaitra ici.")
            st.markdown("<div style='height: 200px;'></div>", unsafe_allow_html=True)

